{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import os\n",
    "import pymysql\n",
    "\n",
    "from dataloader.dataloader import data_loader\n",
    "from utils.data_split import data_split\n",
    "from utils.load_params import load_params\n",
    "from models.train_model import train_model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_squared_log_error, mean_absolute_percentage_error, explained_variance_score\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DB connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostname = \"10.28.224.84\"\n",
    "port = 30234\n",
    "user = \"dogeol\" # dogeol/\n",
    "password = \"1234\"\n",
    "db = \"testdb\"\n",
    "\n",
    "mysql = pymysql.connect(host = hostname, port = port, user = user, password = password, db = db)\n",
    "cursor = mysql.cursor(pymysql.cursors.DictCursor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"pure\" # pure\n",
    "model_name = \"LGBM\" # LGBM/\n",
    "split_type = \"time\" # random/time\n",
    "model_type = \"regressor\" # classifier/regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "date_code = \"\".join([str(now.month), str(now.day), str(now.hour), str(now.minute)])\n",
    "save_name = \"_\".join([model_name, dataset_name, split_type, date_code, \".csv\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, submission_df , drop_columns, target_column = data_loader(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = data_split(split_type, train_df, target_column)\n",
    "X_test = test_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 972\n",
      "[LightGBM] [Info] Number of data points in the train set: 1594362, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 37814.733261\n"
     ]
    }
   ],
   "source": [
    "params = load_params(model_name, model_type)\n",
    "model = train_model(model_name, model_type, params, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_pred = model.predict(x_valid)\n",
    "\n",
    "y_valid_mae = mean_absolute_error(y_valid, y_valid_pred)\n",
    "y_valid_mse = mean_squared_error(y_valid, y_valid_pred)\n",
    "y_valid_rmse = np.sqrt(mean_squared_error(y_valid, y_valid_pred))\n",
    "y_valid_r2 = r2_score(y_valid, y_valid_pred)\n",
    "y_valid_msle = mean_squared_log_error(y_valid, y_valid_pred)\n",
    "y_valid_mape = mean_absolute_percentage_error(y_valid, y_valid_pred)\n",
    "y_valid_evs = explained_variance_score(y_valid, y_valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 6549.25\n",
      "MSE: 109240168.27\n",
      "RMSE: 10451.80\n",
      "R2: 0.87\n",
      "MSLE: 0.06\n",
      "MAPE: 0.18\n",
      "EVS: 0.88\n"
     ]
    }
   ],
   "source": [
    "print(f\"MAE: {y_valid_mae:.2f}\") # 절대 오차의 평균, 값이 작을수록 좋음\n",
    "print(f\"MSE: {y_valid_mse:.2f}\") # 제곱 오차의 평균, 값이 작을수록 좋음\n",
    "print(f\"RMSE: {y_valid_rmse:.2f}\") # MSE의 제곱근, 값이 작을수록 좋음\n",
    "print(f\"R2: {y_valid_r2:.2f}\") # 모델의 설명력, 값이 1에 가까울수록 예측이 정확함\n",
    "print(f\"MSLE: {y_valid_msle:.2f}\") # 예측값과 실제값의 로그 차이를 기반으로 한 평균 제곱 오차, 값이 작을수록 좋음\n",
    "print(f\"MAPE: {y_valid_mape:.2f}\") # 절대 오차를 실제 값에 대한 백분율로 나타낸 값, 값이 작을수록 좋음\n",
    "print(f\"EVS: {y_valid_evs:.2f}\") # 예측된 값과 실제 값 사이의 분산을 측정, 값이 1에 가까울수록 예측이 정확함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 980\n",
      "[LightGBM] [Info] Number of data points in the train set: 1801228, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 38162.229423\n"
     ]
    }
   ],
   "source": [
    "x_total = pd.concat([x_train, x_valid], axis=0)\n",
    "y_total = pd.concat([y_train, y_valid], axis=0)\n",
    "model = train_model(model_name, model_type, params, x_total, y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터가 성공적으로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "date = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "try:\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO recsys_02.result \n",
    "        (date, user, save_name, MAE, MSE, RMSE, R2, MSLE, MAPE, EVS, leaderboard, params) \n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\", \n",
    "    (\n",
    "        date, \n",
    "        user, \n",
    "        save_name, \n",
    "        round(y_valid_mae, 2), \n",
    "        round(y_valid_mse, 2), \n",
    "        round(y_valid_rmse, 2), \n",
    "        round(y_valid_r2, 2), \n",
    "        round(y_valid_msle, 2), \n",
    "        round(y_valid_mape, 2), \n",
    "        round(y_valid_evs, 2), \n",
    "        0, \n",
    "        str(params)\n",
    "    ))\n",
    "\n",
    "    mysql.commit()\n",
    "    print(\"Your data has been saved successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"error : {e}\")\n",
    "\n",
    "finally:\n",
    "    cursor.close()\n",
    "    mysql.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(X_test)\n",
    "submission_df['deposit'] = test_pred\n",
    "submission_df.to_csv(save_name, index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_tech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
