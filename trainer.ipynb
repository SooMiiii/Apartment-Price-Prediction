{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymysql\n",
    "\n",
    "from dataloader.dataloader import data_loader\n",
    "from utils.data_split import data_split\n",
    "from utils.load_params import load_params\n",
    "from utils.mysql import Mysql\n",
    "from models.train_model import train_model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_squared_log_error, mean_absolute_percentage_error, explained_variance_score\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"data_v1017\" # pure/data_v1017\n",
    "model_name = \"LGBM\" # LGBM/XGB/Catboost/\n",
    "split_type = \"time\" # random/time\n",
    "model_type = \"regressor\" # classifier/regressor\n",
    "user = \"soomi\" # hyeongu/dongjoon/dogeol/soomi/yunhye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "date_code = \"\".join([str(now.month), str(now.day), str(now.hour), str(now.minute)])\n",
    "save_name = \"_\".join([model_name, dataset_name, split_type, date_code, \".csv\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df, submission_df , drop_columns, target_column = data_loader(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = data_split(split_type, train_df, target_column)\n",
    "X_test = test_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.095079 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5538\n",
      "[LightGBM] [Info] Number of data points in the train set: 1518975, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 37881.878384\n"
     ]
    }
   ],
   "source": [
    "params = load_params(model_name, model_type)\n",
    "model = train_model(model_name, model_type, params, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: MSLE could not be calculated due to negative values.\n"
     ]
    }
   ],
   "source": [
    "y_valid_pred = model.predict(x_valid)\n",
    "\n",
    "y_valid_mae = mean_absolute_error(y_valid, y_valid_pred)\n",
    "y_valid_mse = mean_squared_error(y_valid, y_valid_pred)\n",
    "y_valid_rmse = np.sqrt(mean_squared_error(y_valid, y_valid_pred))\n",
    "y_valid_r2 = r2_score(y_valid, y_valid_pred)\n",
    "y_valid_mape = mean_absolute_percentage_error(y_valid, y_valid_pred)\n",
    "y_valid_evs = explained_variance_score(y_valid, y_valid_pred)\n",
    "\n",
    "# MSLE 계산을 try-except 블록으로 감싸서 오류 처리\n",
    "try:\n",
    "    y_valid_msle = mean_squared_log_error(y_valid, y_valid_pred)\n",
    "except ValueError:\n",
    "    print(\"Warning: MSLE could not be calculated due to negative values.\")\n",
    "    y_valid_msle = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 5115.17\n",
      "MSE: 68801706.86\n",
      "RMSE: 8294.68\n",
      "R2: 0.92\n",
      "MSLE: Not available\n",
      "MAPE: 0.15\n",
      "EVS: 0.92\n"
     ]
    }
   ],
   "source": [
    "print(f\"MAE: {y_valid_mae:.2f}\") # 절대 오차의 평균, 값이 작을수록 좋음\n",
    "print(f\"MSE: {y_valid_mse:.2f}\") # 제곱 오차의 평균, 값이 작을수록 좋음\n",
    "print(f\"RMSE: {y_valid_rmse:.2f}\") # MSE의 제곱근, 값이 작을수록 좋음\n",
    "print(f\"R2: {y_valid_r2:.2f}\") # 모델의 설명력, 값이 1에 가까울수록 예측이 정확함\n",
    "if y_valid_msle is not None:\n",
    "    print(f\"MSLE: {y_valid_msle:.2f}\")\n",
    "else:\n",
    "    print(\"MSLE: Not available\") # 예측값과 실제값의 로그 차이를 기반으로 한 평균 제곱 오차, 값이 작을수록 좋음\n",
    "print(f\"MAPE: {y_valid_mape:.2f}\") # 절대 오차를 실제 값에 대한 백분율로 나타낸 값, 값이 작을수록 좋음\n",
    "print(f\"EVS: {y_valid_evs:.2f}\") # 예측된 값과 실제 값 사이의 분산을 측정, 값이 1에 가까울수록 예측이 정확함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.104294 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data points in the train set: 1717610, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 38231.006971\n"
     ]
    }
   ],
   "source": [
    "x_total = pd.concat([x_train, x_valid], axis=0)\n",
    "y_total = pd.concat([y_train, y_valid], axis=0)\n",
    "model = train_model(model_name, model_type, params, x_total, y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your data has been saved successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mysql = Mysql(user)\n",
    "mysql.db_connect()\n",
    "\n",
    "date = now.strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "insert_columns = ['date', 'user', 'save_name', 'MAE', 'MSE', 'RMSE', 'R2', 'MSLE', 'MAPE', 'EVS', 'leaderboard', 'params']\n",
    "insert_values = [\n",
    "    date, \n",
    "    user, \n",
    "    save_name, \n",
    "    round(y_valid_mae, 2), \n",
    "    round(y_valid_mse, 2), \n",
    "    round(y_valid_rmse, 2), \n",
    "    round(y_valid_r2, 2), \n",
    "    y_valid_msle, \n",
    "    round(y_valid_mape, 2), \n",
    "    round(y_valid_evs, 2), \n",
    "    0,\n",
    "    str(params)\n",
    "]\n",
    "\n",
    "mysql.db_insert(insert_columns, insert_values)\n",
    "mysql.db_disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == \"pure\" or dataset_name == \"data_v1017\":\n",
    "    pass\n",
    "else: \n",
    "    y_valid /= x_valid['area_m2'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.098584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5562\n",
      "[LightGBM] [Info] Number of data points in the train set: 1717610, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 38231.006971\n"
     ]
    }
   ],
   "source": [
    "x_total = pd.concat([x_train, x_valid], axis=0)\n",
    "y_total = pd.concat([y_train, y_valid], axis=0)\n",
    "model = train_model(model_name, model_type, params, x_total, y_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == \"pure\" or dataset_name == \"data_v1017\":\n",
    "    test_pred = model.predict(X_test)\n",
    "else: \n",
    "    test_pred = model.predict(X_test) \n",
    "    \n",
    "submission_df['deposit'] = test_pred * X_test['area_m2'].reset_index(drop=True)\n",
    "submission_df.to_csv(save_name, index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_tech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
