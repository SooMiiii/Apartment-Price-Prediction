{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import BallTree\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.stats import skew, kurtosis\n",
    "from prophet import Prophet\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(data_path / 'train.csv')\n",
    "test_df = pd.read_csv(data_path / 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before duplicates removal: (1801228, 10)\n",
      "After duplicates removal: (1717611, 10)\n"
     ]
    }
   ],
   "source": [
    "def remove_duplicates(df):\n",
    "    # index drop\n",
    "    df = df.drop('index', axis=1)\n",
    "    print('Before duplicates removal:', df.shape)\n",
    "    df = df.drop_duplicates()\n",
    "    print('After duplicates removal:', df.shape)\n",
    "    return df\n",
    "\n",
    "train_df = remove_duplicates(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['deposit'] = 0\n",
    "df = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, test_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon_df = df[['latitude', 'longitude']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "park_df = pd.read_csv(data_path / 'parkInfo.csv')\n",
    "subway_df = pd.read_csv(data_path / 'subwayInfo.csv')\n",
    "school_df = pd.read_csv(data_path / 'schoolinfo.csv')\n",
    "interest_df = pd.read_csv(data_path / 'interestRate.csv')\n",
    "interest_df = interest_df.rename(columns={'year_month': 'contract_year_month'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/numpy/lib/shape_base.py:402: RuntimeWarning: Precision loss occurred in moment calculation due to catastrophic cancellation. This occurs when the data are nearly identical. Results may be unreliable.\n",
      "  buff[ind] = asanyarray(func1d(inarr_view[ind], *args, **kwargs))\n"
     ]
    }
   ],
   "source": [
    "# 공원\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat, dlon = lat2 - lat1, lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    return 2 * R * np.arcsin(np.sqrt(a))\n",
    "\n",
    "def create_balltree(df):\n",
    "    coords = df[['latitude', 'longitude']].values\n",
    "    return BallTree(np.deg2rad(coords), metric='haversine')\n",
    "\n",
    "def nearest_park_distance(apartment_coords, park_tree):\n",
    "    distances, _ = park_tree.query(np.deg2rad(apartment_coords), k=1)\n",
    "    return distances.ravel() * 6371\n",
    "\n",
    "def count_parks_in_radius(apartment_coords, park_tree, radius):\n",
    "    return park_tree.query_radius(np.deg2rad(apartment_coords), r=radius/6371, count_only=True)\n",
    "\n",
    "def weighted_park_score(apartment_coords, park_tree, park_df):\n",
    "    distances, indices = park_tree.query(np.deg2rad(apartment_coords), k=10)\n",
    "    distances = distances * 6371\n",
    "    areas = park_df.loc[indices.ravel(), 'area'].values.reshape(distances.shape)\n",
    "    return np.sum(areas / (distances + 1), axis=1)\n",
    "\n",
    "def total_park_area_in_radius(apartment_coords, park_tree, park_df, radius):\n",
    "    indices = park_tree.query_radius(np.deg2rad(apartment_coords), r=radius/6371)\n",
    "    return [park_df.loc[idx, 'area'].sum() for idx in indices]\n",
    "\n",
    "def park_distribution_stats(apartment_coords, park_tree):\n",
    "    distances, _ = park_tree.query(np.deg2rad(apartment_coords), k=5)\n",
    "    distances = distances * 6371\n",
    "    return (\n",
    "        np.mean(distances, axis=1),\n",
    "        np.apply_along_axis(skew, 1, distances),\n",
    "        np.apply_along_axis(kurtosis, 1, distances)\n",
    "    )\n",
    "\n",
    "def create_park_features(train_sample, park_df):\n",
    "    park_tree = create_balltree(park_df)\n",
    "    apartment_coords = train_sample[['latitude', 'longitude']].values\n",
    "\n",
    "    features = pd.DataFrame(index=train_sample.index)\n",
    "    \n",
    "    features['nearest_park_distance'] = nearest_park_distance(apartment_coords, park_tree)\n",
    "    \n",
    "    for radius in [0.5, 1, 2]:\n",
    "        features[f'park_count_{int(radius*1000)}m'] = count_parks_in_radius(apartment_coords, park_tree, radius)\n",
    "        features[f'total_park_area_{int(radius*1000)}m'] = total_park_area_in_radius(apartment_coords, park_tree, park_df, radius)\n",
    "    \n",
    "    features['weighted_park_score'] = weighted_park_score(apartment_coords, park_tree, park_df)\n",
    "    \n",
    "    avg_dist, skewness, kurtosis = park_distribution_stats(apartment_coords, park_tree)\n",
    "    features['avg_distance_5_parks'] = avg_dist\n",
    "    features['park_distance_skewness'] = skewness\n",
    "    features['park_distance_kurtosis'] = kurtosis\n",
    "    \n",
    "    return pd.concat([train_sample, features], axis=1)\n",
    "\n",
    "lat_lon_df = create_park_features(lat_lon_df, park_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대형 공원\n",
    "def create_large_park_features(df, park_df, size_threshold=100000):\n",
    "    # 대형 공원만 필터링\n",
    "    large_parks = park_df[park_df['area'] >= size_threshold].reset_index(drop=True)\n",
    "    \n",
    "    # BallTree 생성\n",
    "    large_park_coords = large_parks[['latitude', 'longitude']].values\n",
    "    large_park_tree = BallTree(np.deg2rad(large_park_coords), metric='haversine')\n",
    "    \n",
    "    # 아파트 좌표\n",
    "    apartment_coords = df[['latitude', 'longitude']].values\n",
    "    \n",
    "    # 새로운 특성 생성\n",
    "    features = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    # 가장 가까운 대형 공원까지의 거리\n",
    "    distances, _ = large_park_tree.query(np.deg2rad(apartment_coords), k=1)\n",
    "    features['nearest_large_park_distance'] = distances.ravel() * 6371  # km로 변환\n",
    "    \n",
    "    # 3km, 5km, 10km 반경 내 대형 공원의 수\n",
    "    for radius in [3, 5, 10]:\n",
    "        count = large_park_tree.query_radius(np.deg2rad(apartment_coords), r=radius/6371, count_only=True)\n",
    "        features[f'large_park_count_{radius}km'] = count\n",
    "    \n",
    "    # 10km 반경 내 대형 공원의 총 면적\n",
    "    indices = large_park_tree.query_radius(np.deg2rad(apartment_coords), r=10/6371)\n",
    "    total_areas = [large_parks.loc[idx, 'area'].sum() if len(idx) > 0 else 0 for idx in indices]\n",
    "    features['total_large_park_area_10km'] = total_areas\n",
    "    \n",
    "    return pd.concat([df, features], axis=1)\n",
    "\n",
    "# 데이터 로드 (이미 전처리된 데이터를 사용한다고 가정)\n",
    "# train_df = pd.read_csv('train_sample.csv')\n",
    "# park_df = pd.read_csv('parkInfo.csv')\n",
    "\n",
    "# 대형 공원 특성 생성\n",
    "lat_lon_df = create_large_park_features(lat_lon_df, park_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지하철\n",
    "\n",
    "# Haversine 공식 함수 정의 (두 지점 간의 거리 계산)\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371  # 지구 반경 (단위: km)\n",
    "    phi1, phi2 = np.radians(lat1), np.radians(lat2)\n",
    "    delta_phi = np.radians(lat2 - lat1)\n",
    "    delta_lambda = np.radians(lon2 - lon1)\n",
    "\n",
    "    a = np.sin(delta_phi / 2) ** 2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "\n",
    "    return R * c  # 결과를 km 단위로 반환\n",
    "\n",
    "# KD-Tree를 사용해 가장 가까운 지하철을 찾는 함수\n",
    "def find_nearest_subway(lat, lon, subway_tree, subway_coordinates):\n",
    "    # 주어진 좌표에 대해 가장 가까운 지하철 역 인덱스 찾기\n",
    "    distance, index = subway_tree.query([lat, lon], k=1)\n",
    "    \n",
    "    # 가장 가까운 지하철 역의 좌표\n",
    "    nearest_subway = subway_coordinates[index]\n",
    "    \n",
    "    # Haversine 공식을 사용하여 거리 계산\n",
    "    dist_km = haversine(lat, lon, nearest_subway[0], nearest_subway[1])\n",
    "    \n",
    "    return dist_km\n",
    "\n",
    "# subway 데이터의 좌표를 KD-Tree로 변환\n",
    "subway_coordinates = subway_df[['latitude', 'longitude']].values\n",
    "subway_tree = cKDTree(subway_coordinates)\n",
    "\n",
    "lat_lon_df['nearest_subway_distance_km'] = lat_lon_df.apply(\n",
    "lambda row: find_nearest_subway(row['latitude'], row['longitude'], subway_tree, subway_coordinates),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학교\n",
    "def calculate_school_distances_with_kdtree(df, schools):\n",
    "    school_locations = schools[['latitude', 'longitude']].values\n",
    "    school_levels = schools['schoolLevel'].values\n",
    "\n",
    "    # KDTree 생성\n",
    "    kdtree = cKDTree(school_locations)\n",
    "\n",
    "    nearby_school_counts = []\n",
    "    closest_schools = {'elementary': [], 'middle': [], 'high': []}\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        current_location = (row['latitude'], row['longitude'])\n",
    "\n",
    "        # KDTree로 주변 학교들의 인덱스와 거리를 구함\n",
    "        distances, indices = kdtree.query(current_location, k=len(school_locations))\n",
    "\n",
    "        # Euclidean distance를 사용하여 1km 이내의 학교만 카운팅\n",
    "        geo_distances = haversine(row['latitude'], row['longitude'], school_locations[:, 0], school_locations[:, 1])\n",
    "        \n",
    "        # 1km 이내의 학교만 카운팅\n",
    "        within_1km = np.where(geo_distances < 1.0)[0]\n",
    "        nearby_school_count = len(within_1km)\n",
    "\n",
    "        # 가장 가까운 초등학교, 중학교, 고등학교의 거리 계산\n",
    "        for level in ['elementary', 'middle', 'high']:\n",
    "            level_indices = indices[school_levels[indices] == level]\n",
    "            if len(level_indices) > 0:\n",
    "                closest_school_distance = geo_distances[level_indices[0]]\n",
    "            else:\n",
    "                closest_school_distance = np.nan  # 해당 학교가 없을 경우\n",
    "\n",
    "            closest_schools[level].append(closest_school_distance)\n",
    "\n",
    "        nearby_school_counts.append(nearby_school_count)\n",
    "\n",
    "    # 결과를 DataFrame에 추가\n",
    "    df['school_count_within_1km'] = nearby_school_counts\n",
    "    df['closest_elementary_distance'] = closest_schools['elementary']\n",
    "    df['closest_middle_distance'] = closest_schools['middle']\n",
    "    df['closest_high_distance'] = closest_schools['high']\n",
    "\n",
    "    return df\n",
    "\n",
    "lat_lon_df = calculate_school_distances_with_kdtree(lat_lon_df, school_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>nearest_park_distance</th>\n",
       "      <th>park_count_500m</th>\n",
       "      <th>total_park_area_500m</th>\n",
       "      <th>park_count_1000m</th>\n",
       "      <th>total_park_area_1000m</th>\n",
       "      <th>park_count_2000m</th>\n",
       "      <th>total_park_area_2000m</th>\n",
       "      <th>weighted_park_score</th>\n",
       "      <th>...</th>\n",
       "      <th>nearest_large_park_distance</th>\n",
       "      <th>large_park_count_3km</th>\n",
       "      <th>large_park_count_5km</th>\n",
       "      <th>large_park_count_10km</th>\n",
       "      <th>total_large_park_area_10km</th>\n",
       "      <th>nearest_subway_distance_km</th>\n",
       "      <th>school_count_within_1km</th>\n",
       "      <th>closest_elementary_distance</th>\n",
       "      <th>closest_middle_distance</th>\n",
       "      <th>closest_high_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.054314</td>\n",
       "      <td>127.045216</td>\n",
       "      <td>0.498619</td>\n",
       "      <td>1</td>\n",
       "      <td>3898.0</td>\n",
       "      <td>6</td>\n",
       "      <td>198124.0</td>\n",
       "      <td>56</td>\n",
       "      <td>1735804.3</td>\n",
       "      <td>144540.902558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.940079</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>3082215.1</td>\n",
       "      <td>0.716953</td>\n",
       "      <td>4</td>\n",
       "      <td>0.156120</td>\n",
       "      <td>0.465125</td>\n",
       "      <td>0.990855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.964647</td>\n",
       "      <td>127.055847</td>\n",
       "      <td>0.169840</td>\n",
       "      <td>3</td>\n",
       "      <td>3809.0</td>\n",
       "      <td>13</td>\n",
       "      <td>105702.1</td>\n",
       "      <td>23</td>\n",
       "      <td>286268.1</td>\n",
       "      <td>59250.149092</td>\n",
       "      <td>...</td>\n",
       "      <td>5.207932</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1877924.1</td>\n",
       "      <td>3.897280</td>\n",
       "      <td>4</td>\n",
       "      <td>0.214560</td>\n",
       "      <td>0.688047</td>\n",
       "      <td>0.644366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.972390</td>\n",
       "      <td>127.084514</td>\n",
       "      <td>0.382402</td>\n",
       "      <td>1</td>\n",
       "      <td>3986.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3986.0</td>\n",
       "      <td>13</td>\n",
       "      <td>37137.4</td>\n",
       "      <td>14232.664397</td>\n",
       "      <td>...</td>\n",
       "      <td>3.137452</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2199482.1</td>\n",
       "      <td>2.039685</td>\n",
       "      <td>0</td>\n",
       "      <td>1.708489</td>\n",
       "      <td>2.197946</td>\n",
       "      <td>2.264822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36.965423</td>\n",
       "      <td>127.048779</td>\n",
       "      <td>0.288443</td>\n",
       "      <td>3</td>\n",
       "      <td>35950.3</td>\n",
       "      <td>11</td>\n",
       "      <td>76504.3</td>\n",
       "      <td>24</td>\n",
       "      <td>384727.1</td>\n",
       "      <td>48590.986555</td>\n",
       "      <td>...</td>\n",
       "      <td>5.443829</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1877924.1</td>\n",
       "      <td>4.284771</td>\n",
       "      <td>2</td>\n",
       "      <td>0.779057</td>\n",
       "      <td>1.313939</td>\n",
       "      <td>1.264233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36.957089</td>\n",
       "      <td>127.047449</td>\n",
       "      <td>0.272286</td>\n",
       "      <td>2</td>\n",
       "      <td>106172.0</td>\n",
       "      <td>12</td>\n",
       "      <td>258583.3</td>\n",
       "      <td>21</td>\n",
       "      <td>283702.1</td>\n",
       "      <td>143177.065595</td>\n",
       "      <td>...</td>\n",
       "      <td>6.299737</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1877924.1</td>\n",
       "      <td>5.021184</td>\n",
       "      <td>1</td>\n",
       "      <td>0.808416</td>\n",
       "      <td>1.514929</td>\n",
       "      <td>1.448064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    latitude   longitude  nearest_park_distance  park_count_500m  \\\n",
       "0  37.054314  127.045216               0.498619                1   \n",
       "3  36.964647  127.055847               0.169840                3   \n",
       "4  36.972390  127.084514               0.382402                1   \n",
       "5  36.965423  127.048779               0.288443                3   \n",
       "6  36.957089  127.047449               0.272286                2   \n",
       "\n",
       "   total_park_area_500m  park_count_1000m  total_park_area_1000m  \\\n",
       "0                3898.0                 6               198124.0   \n",
       "3                3809.0                13               105702.1   \n",
       "4                3986.0                 1                 3986.0   \n",
       "5               35950.3                11                76504.3   \n",
       "6              106172.0                12               258583.3   \n",
       "\n",
       "   park_count_2000m  total_park_area_2000m  weighted_park_score  ...  \\\n",
       "0                56              1735804.3        144540.902558  ...   \n",
       "3                23               286268.1         59250.149092  ...   \n",
       "4                13                37137.4         14232.664397  ...   \n",
       "5                24               384727.1         48590.986555  ...   \n",
       "6                21               283702.1        143177.065595  ...   \n",
       "\n",
       "   nearest_large_park_distance  large_park_count_3km  large_park_count_5km  \\\n",
       "0                     0.940079                     5                     8   \n",
       "3                     5.207932                     0                     0   \n",
       "4                     3.137452                     0                     4   \n",
       "5                     5.443829                     0                     0   \n",
       "6                     6.299737                     0                     0   \n",
       "\n",
       "   large_park_count_10km  total_large_park_area_10km  \\\n",
       "0                     14                   3082215.1   \n",
       "3                      7                   1877924.1   \n",
       "4                      8                   2199482.1   \n",
       "5                      7                   1877924.1   \n",
       "6                      7                   1877924.1   \n",
       "\n",
       "   nearest_subway_distance_km  school_count_within_1km  \\\n",
       "0                    0.716953                        4   \n",
       "3                    3.897280                        4   \n",
       "4                    2.039685                        0   \n",
       "5                    4.284771                        2   \n",
       "6                    5.021184                        1   \n",
       "\n",
       "   closest_elementary_distance  closest_middle_distance  closest_high_distance  \n",
       "0                     0.156120                 0.465125               0.990855  \n",
       "3                     0.214560                 0.688047               0.644366  \n",
       "4                     1.708489                 2.197946               2.264822  \n",
       "5                     0.779057                 1.313939               1.264233  \n",
       "6                     0.808416                 1.514929               1.448064  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat_lon_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['latitude', 'longitude', 'nearest_park_distance', 'park_count_500m',\n",
       "       'total_park_area_500m', 'park_count_1000m', 'total_park_area_1000m',\n",
       "       'park_count_2000m', 'total_park_area_2000m', 'weighted_park_score',\n",
       "       'avg_distance_5_parks', 'park_distance_skewness',\n",
       "       'park_distance_kurtosis', 'nearest_large_park_distance',\n",
       "       'large_park_count_3km', 'large_park_count_5km', 'large_park_count_10km',\n",
       "       'total_large_park_area_10km', 'nearest_subway_distance_km',\n",
       "       'school_count_within_1km', 'closest_elementary_distance',\n",
       "       'closest_middle_distance', 'closest_high_distance'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat_lon_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(lat_lon_df, on=['latitude', 'longitude'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09:32:27 - cmdstanpy - INFO - Chain [1] start processing\n",
      "09:32:27 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "# Train_df에서 contract_year_month가 같은 row들의 deposit 평균을 column으로 추가\n",
    "train_df['deposit_mean'] = train_df.groupby('contract_year_month')['deposit'].transform('mean')\n",
    "\n",
    "# deposit_mean을 interest_rate_df에 추가 하나씩만\n",
    "interest_rate_df = pd.merge(interest_df, train_df[['contract_year_month', 'deposit_mean']], on='contract_year_month', how='left')\n",
    "# unique한 contract_year_month만 남기기\n",
    "interest_rate_df.drop_duplicates(subset='contract_year_month', keep='first', inplace=True)\n",
    "# index 초기화\n",
    "interest_rate_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# contract_year_month 202406 추가 하고 interest_rate 4칸(최대) shift\n",
    "interest_rate_df = pd.concat([interest_rate_df, pd.DataFrame({'contract_year_month': [202406], 'interest_rate': [0]})])\n",
    "# index는 contract_year_month로\n",
    "interest_rate_df.set_index('contract_year_month', inplace=True)\n",
    "# index 순서대로 정렬\n",
    "interest_rate_df.sort_index(inplace=True)\n",
    "interest_rate_df['interest_rate'] = interest_rate_df['interest_rate'].shift(4)\n",
    "\n",
    "# 이전 금리와 차이값 feature 추가\n",
    "interest_rate_df['interest_rate_diff'] = interest_rate_df['interest_rate'].diff()\n",
    "\n",
    "# 2019 04 이후 데이터만 사용\n",
    "interest_rate_df = interest_rate_df[interest_rate_df.index >= 201904]\n",
    "\n",
    "# index feature로 사용하기 위해 reset_index\n",
    "interest_rate_df.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "# interest_rate_df에서 필요한 컬럼만 선택\n",
    "# contract_year_month datetime으로 변환\n",
    "interest_rate_df['contract_year_month'] = pd.to_datetime(interest_rate_df['contract_year_month'], format='%Y%m')\n",
    "\n",
    "df_prophet = interest_rate_df[['contract_year_month', 'deposit_mean', 'interest_rate']].copy()\n",
    "\n",
    "\n",
    "# Prophet이 인식할 수 있도록 컬럼명 변경\n",
    "df_prophet.rename(columns={'contract_year_month': 'ds', 'deposit_mean': 'y'}, inplace=True)\n",
    "# 모델 정의\n",
    "model = Prophet()\n",
    "model.add_regressor('interest_rate')\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(df_prophet.dropna())\n",
    "\n",
    "# 미래 데이터프레임 생성\n",
    "# ds 2024-01-01 ~ 2024-05-01\n",
    "# 예측 수행\n",
    "future = model.make_future_dataframe(periods=6, freq='MS')\n",
    "future['interest_rate'] = df_prophet['interest_rate']\n",
    "forecast = model.predict(future)\n",
    "# interest_rate_df에 merge\n",
    "interest_rate_df = pd.merge(interest_rate_df, forecast[['ds', 'trend']], left_on='contract_year_month', right_on='ds', how='left')\n",
    "\n",
    "# trend의 2024-01-01 ~ 2024-06-01 값만 interest_rate_df의 deposit_mean에 대입\n",
    "interest_rate_df.loc[interest_rate_df['contract_year_month'] >= '2024-01-01', 'deposit_mean'] = interest_rate_df.loc[interest_rate_df['contract_year_month'] >= '2024-01-01', 'trend'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_rate_df['contract_year_month'] = interest_rate_df['contract_year_month'].dt.strftime('%Y%m').astype(int)\n",
    "df = pd.merge(df, interest_rate_df[['contract_year_month', 'deposit_mean', 'interest_rate', 'interest_rate_diff']], on='contract_year_month', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"merged_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"merged_data.csv.gz\", index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
